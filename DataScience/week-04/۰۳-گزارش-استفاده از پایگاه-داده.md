<p align="center">بسم الله الرحمن الرحیم</p>
# جزئیات عملیاتی
- سیستم عامل: اوبونتو 22.04.5 LTS
   - استقرار: docker
- سرویس‌های موجود در راه‌حل:
    - پایگاه داده NoSQL: Elasticsearch 9.1.5
    - ابزار تجسم داده‌ها: Kibana 9.1.5
    - پایگاه داده SQL: PostgreSQL 16.10-alpine3.22
    - زمان‌بندی و مدیریت: Airflow 2.9.2
    - زمان‌بندی و مدیریت: NiFi 1.27.0
- نسخه گزارش: 0.1
- تاریخ نگارش: ۲۳ آبان‌ماه ۱۴۰۴
- علی جمعه‌ئی به شماره دانش‌جویی 404723864

# صورت مسئله
می‌خواهیم برای استفاده از پایگاه داده در خط فرمان آماده شویم و نوشتن و خواندن در آن را تمرین کنیم.

# یادداشت‌ها و مراحل کار

## پایگاه داده Postgresql

### نصب psycopg2

```bash
pip install psycopg2-binary
```
به نظر نسخه‌ی سوم این ماژول نیز وجود دارد که ویژگی‌های جدید در آن منتشر می‌شوند اما مطابق کتاب و به این دلیل که منسوخ نشده بود از همان نسخه دو استفاده کردم.

### ساخت پایگاه داده و جدول
#### ورود به خط فرمان کانتینر postgresql

```bash
docker exec -it postgres psql -U airflow
```
در خط بالا از نام کاربری `airflow` استفاده شده، چرا که قبلا در داکر کامپوز از آن استفاده کردیم.

``` sql
CREATE ROLE admin WITH LOGIN SUPERUSER PASSWORD 'adminpass'; 
```

برای این که کار تمیزتر باشد و با نام کاربری airflow کار دیگری انجام ندهیم کابر ادمین را می‌سازیم و دوباره با آن وارد خط فرمان postgresql در کانتینر می‌شویم

```bash
docker exec -it postgres psql -U admin -d postgres
```

سپس اقدام به ساخت پایگاه داده `dataengineering` می‌کنیم.

```sql
CREATE DATABASE dataengineering;
```

دوباره خارج شده و با `admin` به پایگاه داده `dataengineering` متصل می‌شویم

```bash
docker exec -it postgres psql -U admin -d dataengineering
```

با استفاده از دستور زیر جدول را می‌سازیم

```sql
CREATE TABLE users (
    id SERIAL PRIMARY KEY,
    name TEXT,
    street TEXT,
    city TEXT,
    zip TEXT
);
```

### کار با Postgresqsl در پایتون
####  نوشتن در postgresql
با استفاده از کد پایتون زیر که در کتاب آمده یک ردیف جدید در جدول users ایجاد شد

```python
import psycopg2 as db

connection_string = (
    "dbname='dataengineering' host='192.168.21.81' user='admin' password='adminpass'"
)
connection = db.connect(connection_string)
cursor = connection.cursor()

query = "insert into users (id,name,street,city,zip) values(%s,%s,%s,%s,%s)"
data = (1, "Big Bird", "Sesame Street", "Fakeville", "12345")
cursor.mogrify(query, data)
cursor.execute(query, data)

connection.commit()
```

پس از اجرای اسکریپت بالا برای اطمینان دستور و نتیجه زیر در db نوشته و حاصل شد.
``` sql
dataengineering=# select * from users;
 id |   name   |    street     |   city    |  zip
----+----------+---------------+-----------+-------
  1 | Big Bird | Sesame Street | Fakeville | 12345
(1 row)
```

#### نوشتن داده‌های زیاد

همین‌طور با کد زیر ۱۰۰۰ ردیف جدید در پایگاه داده نوشته شد

```python
import psycopg2 as db
from faker import Faker

fake = Faker()
data = []
connection_string = (
    "dbname='dataengineering' host='192.168.21.81' user='admin' password='adminpass'"
)

connection = db.connect(connection_string)
cursor = connection.cursor()

for i in range(1000):
    data.append(
        (i + 2, fake.name(), fake.street_address(), fake.city(), fake.zipcode())
    )
  
data = tuple(data)
query = "insert into users (id,name,street,city,zip) values(%s,%s,%s,%s,%s)"
print(cursor.mogrify(query, data[1]))
cursor.executemany(query, data)
connection.commit()
```

و ورود درست داده‌ها با اعمال دستورهای زیر و نتایج آن بررسی شد.

```sql
dataengineering=# select * from users where id=10;
 id |      name      |       street        |        city         |  zip
----+----------------+---------------------+---------------------+-------
 10 | Colton Vasquez | 700 Julie Crossroad | North Samanthaville | 65884
(1 row)

dataengineering=# select * from users where id=608;
 id  |      name       |      street       |   city    |  zip
-----+-----------------+-------------------+-----------+-------
 608 | Thomas Anderson | 41550 Mark Bypass | Katiefurt | 21215
(1 row)
```

#### خواندن اطلاعات

```python
import psycopg2 as db
from faker import Faker
  

class ConnectionPG:
    def __init__(self, dbname, host, user, password, base_query):
        self._connection_string = (
            f"dbname='{dbname}' host='{host}' user='{user}' password='{password}'"
        )
        self._connection = db.connect(self._connection_string)
        self._cursor = self._connection.cursor()
        self._base_query = base_query
        pass

    def insert_raw(self, data):
        self._cursor.execute(self._base_query, data)
        pass

    def insert_multiple_raw(self, data: list):
        temp = tuple(data)
        self._cursor.executemany(self._base_query, temp)
        pass
  
    def test_insert_many(self):
        fake = Faker()
        data = []
        for i in range(1000):
            data.append(
                (fake.name(), fake.street_address(), fake.city(), fake.zipcode())
            )
        self.insert_multiple_raw(data=data)
        pass
  
    def test_insert_single(self):
        fake = Faker()
        data = (fake.name(), fake.street_address(), fake.city(), fake.zipcode())
        self.insert_raw(data=data)
        pass
  
    def print_db_record(self):
        query = "select * from users;"
        self._cursor.execute(query)
        for record in self._cursor:
            print(record)
        pass
  

if __name__ == "__main__":
    pg = ConnectionPG(
        dbname="dataengineering",
        host="192.168.21.81",
        user="admin",
        password="adminpass",
        base_query="insert into users (id,name,street,city,zip) values(%s,%s,%s,%s,%s)",
    )
    pg.print_db_record()
```

بخشی از خروجی اجرای اسکریپت بالا

```bash
(984, 'Jeffrey Thomas', '44874 Williams Freeway Suite 914', 'Jeffreyfort', '06308')
(985, 'Eric Miller', '6522 Monica Rapid', 'Lake Hollystad', '85437')
(986, 'Denise Brooks', '8513 Wilson Stravenue', 'Sandersmouth', '36367')
(987, 'Cassandra Haynes', '9740 David Forge Apt. 634', 'Maryview', '99769')
(988, 'Jennifer Thompson', '008 Simmons Trafficway Apt. 430', 'Virginiaview', '76943')
(989, 'Jamie Fletcher DDS', '94907 Ibarra Shoal Suite 899', 'Jamesbury', '29404')
(990, 'Christopher Lopez', '52111 Gonzalez Vista Suite 045', 'Taylorstad', '67477')
(991, 'Melissa Taylor', '094 Erika Plaza', 'Reyesfort', '47689')
(992, 'Christy Holmes', '6998 Morris Cape', 'Andersonstad', '82656')
```

#### نوشتن در csv
```python
class ConnectionPG:
# خطوط قبلی کد
    def write_db_to_csf(self):
        query = "select * from users;"
        self._cursor.execute(query)
        csv_file = open("fromdb.csv", "w")
        self._cursor.copy_to(csv_file, "users", sep=",")
        csv_file.close()
        pass
# خطوط بعدی کد
```

اجرای تابع بالا فایل cvs می‌سازد که حاوی همه اطلاعات جدول است. [این csv](./fromdb.csv) در این سری در کنار همین فایل وجود دارد

#### بارگذاری در data frame در pandas

```python
class ConnectionPG:
# خطوط قبلی کد
    def load_db_in_pandas(self):
        return pd.read_sql("select * from users where id=400", self._connection)
 # خطوط کد
if __name__ == "__main__":
    frame = pg.load_db_in_pandas()
    print(frame.to_json(orient='records'))
```

خروجی به شکل زیر است (id=400) گذاشته شده تا خروجی محدود و قابل نمایش در این‌جا باشد اما اگر از where به بعد حذف شود همه‌ی ردیف‌ها در خروجی خواهد بود
```bash
/root/apg/iust/DataScience/week-04/psql_pg.py:57: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.
  return pd.read_sql("select * from users where id=400", self._connection)
[{"id":400,"name":"Zachary Spencer","street":"855 Matthew Station Apt. 704","city":"Smithbury","zip":"13705"}]
```


## پایگاه داده Elasticsearch

### نصب ماژول پایتون

```bash
pip install elasticsearch
```

### نوشتن به صورت index در elastic search

```python
from elasticsearch import Elasticsearch
from faker import Faker
  
 
class EsConnectionPg:
    def __init__(self, host: str):
        self._es = Elasticsearch(hosts=[host])
  
    def insert_index(self, doc: dict):
        return self._es.index(index="users", document=doc)
  
 
if __name__ == "__main__":
    fake = Faker()
    espg = EsConnectionPg("http://192.168.21.81:9200")
  
    doc = {
        "name": fake.name(),
        "street": fake.street_address(),
        "city": fake.city(),
        "zip": fake.zipcode(),
    }
  
    result = espg.insert_index(doc)
    print(result)
```

از آن‌جا که نسخه استفاده شده در کتاب و این‌جا کمی متفاوت است، بنابراین صورت نگارشی دقیق کتاب خطا داشت و نیاز به کمی اصلاح بود. خروجی اجرای اسکریپت بالا

```bash
{'_index': 'users', '_id': 'YO5ZgpoBjkp41JfgSttT', '_version': 1, 'result': 'created', '_shards': {'total': 2, 'successful': 1, 'failed': 0}, '_seq_no': 0, '_primary_term': 1}
```

همین طور در kibana شاهد اضافه شدن این ردیف بودیم.
![[kibana-screen-shot.png]]

### نوشتن در elastic search با helper

```python
# خطوط قبلی کد
    def test_helper_insert(self):
        actions = [
            {
                "_index": "users",
                "_source": {
                    "name": self._faker.name(),
                    "street": self._faker.street_address(),
                    "city": self._faker.city(),
                    "zip": self._faker.zipcode(),
                },
            }
            for _ in range(998)
        ]
        return helpers.bulk(self._es, actions)
# خطوط بعدی کد
```

### درخواست‌هایی از elastic search
```python
# خطوط قبلی کد
    def query_es(self):
        doc = {"query": {"match_all": {}}}
        return self._es.search(index="users",body=doc,size=10)
# خطوط بعدی کد
result = espg.query_es()
print(dir(result))
print(result.body)
```

خروجی:
```bash
/root/apg/iust/DataScience/week-04/es_pg.py:31: DeprecationWarning: Received 'size' via a specific parameter in the presence of a 'body' parameter, which is deprecated and will be removed in a future version. Instead, use only 'body' or only specific parameters.
  return self._es.search(index="users",body=doc,size=10)
['__bool__', '__class__', '__class_getitem__', '__contains__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__orig_bases__', '__parameters__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_body', '_is_protocol', '_meta', 'body', 'meta', 'raw']
{'took': 0, 'timed_out': False, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 999, 'relation': 'eq'}, 'max_score': 1.0, 'hits': [{'_index': 'users', '_id': 'YO5ZgpoBjkp41JfgSttT', '_score': 1.0, '_source': {'name': 'Patrick Gibbs', 'street': '24390 Tonya Station', 'city': 'Edwardshaven', 'zip': '20945'}}, {'_index': 'users', '_id': 'Ye5kgpoBjkp41JfgrNvB', '_score': 1.0, '_source': {'name': 'Arthur Randolph', 'street': '91346 Amanda Bypass Apt. 902', 'city': 'Aguirreshire', 'zip': '12273'}}, {'_index': 'users', '_id': 'Yu5kgpoBjkp41JfgrNvB', '_score': 1.0, '_source': {'name': 'Hector Anderson', 'street': '396 Hays Loop', 'city': 'East Kristenborough', 'zip': '63075'}}, {'_index': 'users', '_id': 'Y-5kgpoBjkp41JfgrNvB', '_score': 1.0, '_source': {'name': 'Stephen Thomas', 'street': '38773 Lloyd Field Suite 564', 'city': 'Hallview', 'zip': '63792'}}, {'_index': 'users', '_id': 'ZO5kgpoBjkp41JfgrNvB', '_score': 1.0, '_source': {'name': 'Matthew Wise', 'street': '6896 Richard Keys Apt. 831', 'city': 'Lake Nancy', 'zip': '64037'}}, {'_index': 'users', '_id': 'Ze5kgpoBjkp41JfgrNvB', '_score': 1.0, '_source': {'name': 'Carla Watson', 'street': '321 Long Extension', 'city': 'Melissaville', 'zip': '52219'}}, {'_index': 'users', '_id': 'Zu5kgpoBjkp41JfgrNvB', '_score': 1.0, '_source': {'name': 'Stephen Foster', 'street': '3509 Holder Path Suite 936', 'city': 'Gentryhaven', 'zip': '49968'}}, {'_index': 'users', '_id': 'Z-5kgpoBjkp41JfgrNvB', '_score': 1.0, '_source': {'name': 'Joel Gonzalez', 'street': '36171 Williams Island Suite 927', 'city': 'Port Ivan', 'zip': '91191'}}, {'_index': 'users', '_id': 'aO5kgpoBjkp41JfgrNvB', '_score': 1.0, '_source': {'name': 'Duane Rodriguez', 'street': '638 Danielle Inlet', 'city': 'South Pedrotown', 'zip': '28860'}}, {'_index': 'users', '_id': 'ae5kgpoBjkp41JfgrNvB', '_score': 1.0, '_source': {'name': 'Amanda Gallegos', 'street': '318 Cook Gardens', 'city': 'New Dianehaven', 'zip': '55656'}}]}}
```

## استفاده از airflow

با استفاده از کد زیر در مسیر DAGهای airflow فعالیت انجام شد

```python
import datetime as dt
from datetime import timedelta
  
from datetime import datetime, timedelta  
from airflow.providers.standard.operators.python import PythonOperator
  
from airflow.sdk import DAG
import pandas as pd
import psycopg2 as db
from elasticsearch import Elasticsearch
  
 
class PostgresqlConnectionPg:
    def __init__(self, dbname, host, user, password, base_query):
        self._connection_string = (
            f"dbname='{dbname}' host='{host}' user='{user}' password='{password}'"
        )
        self._connection = db.connect(self._connection_string)
        self._cursor = self._connection.cursor()
        self._base_query = base_query
        pass

    def write_db_to_csv(self, csv_file_name: str):
        query = "select * from users;"
        self._cursor.execute(query)
        csv_file = open(csv_file_name, "w")
        self._cursor.copy_to(csv_file, "users", sep=",")
        csv_file.close()
        pass


ps = PostgresqlConnectionPg(
    dbname="dataengineering",
    host="192.168.21.81",
    user="admin",
    password="adminpass",
    base_query="insert into users (id,name,street,city,zip) values(%s,%s,%s,%s,%s)",
)
  
 
def queryPostgresql():
    ps.write_db_to_csv("postgresqldata.csv")
    print("-------Data Saved------")
  
 
def insertElasticsearch():
    es = Elasticsearch("http://192.168.21.81:9200")
    df = pd.read_csv("postgresqldata.csv")
    for i, r in df.iterrows():
        doc = r.to_json()
        res = es.index(index="frompostgresql", doc_type="doc", body=doc)
        print(res)
  
 
with DAG(
    "psql-to-es",
    default_args={
        "depends_on_past": False,
        "retries": 1,
        "retry_delay": timedelta(hours=2),
    },
    description="Chapter 4 Implementation",
    schedule=timedelta(days=1),
    start_date=datetime(2021, 1, 1),
    catchup=False,
    tags=["data-pipline-pg"],
) as dag:
  
    getData = PythonOperator(task_id="QueryPostgreSQL", python_callable=queryPostgresql)
 
    insertData = PythonOperator(
        task_id="InsertDataElasticsearch", python_callable=insertElasticsearch
    )
getData >> insertData
```

گفتنی است که این کد اختلاف جزیی با کتاب دارد که به دلیل اختلاف نسخه airflow است. نتیجه استفاده از این پایپ‌لاین متاسفانه موفقیت آمیز نبود که تا زمان ارسال این پاسخ نتوانستم منشا خطا را پیدا کنم
![[airflow-dag-error.png]]


## استفاده از nifi
![[nifi-pipeline.png]]
مطابق توضیح کتاب این pipeline ساخته شده است اما دو خطا وجود دارد که در فرصت موجود به رفع آن‌ها نرسیدم، خطای اول
![[nifi-pipeline-first-error.png]]
و خطای دوم
![[nifi-pipeline-second-error.png]]


پایان
